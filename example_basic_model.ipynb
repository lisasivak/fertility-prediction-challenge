{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1fdf6e-74e0-40e0-8742-e372008b3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"polars[numpy, pandas]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b20e5c6-1097-45d2-9fca-04ddaf8b0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow\n",
    "#import pyarrow\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c7eccb-48df-4db4-a660-3358045f7855",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_pandas \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mlisch\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m3D Objects\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mPreFer_data\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mfor participants\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtraining_data\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mPreFer_train_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prefer\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prefer\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prefer\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\prefer\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mparsers.pyx:820\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:914\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
     ]
    }
   ],
   "source": [
    "train_pandas = pd.read_csv(\"C:\\\\Users\\\\lisch\\\\3D Objects\\\\PreFer_data\\\\for participants\\\\training_data\\\\PreFer_train_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc42ff5-9a36-47f7-a1d8-92be81b8a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(\"C:\\\\Users\\\\lisch\\\\3D Objects\\\\PreFer_data\\\\for participants\\\\training_data\\\\PreFer_train_data.csv\", infer_schema_length=10000)#.to_pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f57443-d3a2-4c26-af2b-b5c2db20c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pl_to_pd = pl.read_csv(\"C:\\\\Users\\\\lisch\\\\3D Objects\\\\PreFer_data\\\\for participants\\\\training_data\\\\PreFer_train_data.csv\", infer_schema_length=10000).to_pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5a3f0-eb58-44cd-a704-59a20384c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting types in pandas\n",
    "types_pan = train_pandas.dtypes\n",
    "\n",
    "Counter(types_pan)\n",
    "#types_pan[31408]\n",
    "\n",
    "\n",
    "#train_pandas['birthyear_bg'].dtype\n",
    "\n",
    "#df = train_pandas.select_dtypes(include=['int64'])\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dbf87-b7c4-4682-97a2-ae712bcb184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting types in polars\n",
    "types_pl = train.dtypes\n",
    "\n",
    "Counter(types_pl)\n",
    "types_pl[31407]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53895979-78b1-4121-8621-baf83cb2775e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({dtype('float64'): 27284, dtype('O'): 4346, dtype('int64'): 4})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting types in polars to pandas\n",
    "types_pl_to_pd = train_pl_to_pd.dtypes\n",
    "\n",
    "Counter(types_pl_to_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a56d98-7f16-419e-b526-bbce78273568",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cd19l024'].value_counts()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff008674-fcbb-4051-ac27-d1172f5659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pd.read_csv(\"C:\\\\Users\\\\lisch\\\\3D Objects\\\\ODISSEI Summer School 2023 - Gert & Lisa\\\\ODISSEI Summer School 2023 - Gert Stulp\\\\1PreFer data for Eyra\\\\training_FOR PARTICIPANTS\\\\PreFer_train_outcome.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1602a-c245-4daa-a07f-6db5c43dc618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, background_df=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input dataframe to feed the model.\n",
    "    # If no cleaning is done (e.g. if all the cleaning is done in a pipeline) leave only the \"return df\" command\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing the raw data (e.g., from PreFer_train_data.csv or PreFer_fake_data.csv).\n",
    "    background (pd.DataFrame): Optional input dataframe containing background data (e.g., from PreFer_train_background_data.csv or PreFer_fake_background_data.csv).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The cleaned dataframe with only the necessary columns and processed variables.\n",
    "    \"\"\"\n",
    "\n",
    "    ## This script contains a bare minimum working example\n",
    "    # Create new variable with age\n",
    "    df[\"age\"] = 2024 - df[\"birthyear_bg\"]\n",
    "\n",
    "    # Imputing missing values in age with the mean\n",
    "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].mean())\n",
    "\n",
    "    # Selecting variables for modelling\n",
    "    keepcols = [\n",
    "        \"nomem_encr\",  # ID variable required for predictions,\n",
    "        \"age\"         # newly created variable\n",
    "        ,\"gender_bg\"  # <--------ADDED VARIABLE\n",
    "    ] \n",
    "\n",
    "    # Keeping data with variables selected\n",
    "    df = df[keepcols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c3427-a2cf-4744-83a5-2e72b8286e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save_model(cleaned_df, outcome_df):\n",
    "    \"\"\"\n",
    "    Trains a model using the cleaned dataframe and saves the model to a file.\n",
    "\n",
    "    Parameters:\n",
    "    cleaned_df (pd.DataFrame): The cleaned data from clean_df function to be used for training the model.\n",
    "    outcome_df (pd.DataFrame): The data with the outcome variable (e.g., from PreFer_train_outcome.csv or PreFer_fake_outcome.csv).\n",
    "    \"\"\"\n",
    "    \n",
    "    ## This script contains a bare minimum working example\n",
    "    #random.seed(1) # not useful here because logistic regression deterministic\n",
    "    \n",
    "    # Combine cleaned_df and outcome_df\n",
    "    model_df = pd.merge(cleaned_df, outcome_df, on=\"nomem_encr\")\n",
    "\n",
    "    # Filter cases for whom the outcome is not available\n",
    "    model_df = model_df[~model_df['new_child'].isna()]  \n",
    "    \n",
    "    # Logistic regression model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(model_df[['age', 'gender_bg']], model_df['new_child']) # <-------- ADDED VARIABLE\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77270f36-12f3-4188-bead-3aa2c1cea3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "train_cleaned = clean_df(train)\n",
    "# training and saving the model\n",
    "train_save_model(train_cleaned, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d0b53-d89c-4e93-bc39-108ca4a40495",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"PreFer_fake_data.csv\")\n",
    "\n",
    "def predict_outcomes(df, background_df=None, model_path=\"model.joblib\"):\n",
    "    \"\"\"Generate predictions using the saved model and the input dataframe.\n",
    "\n",
    "    The predict_outcomes function accepts a Pandas DataFrame as an argument\n",
    "    and returns a new DataFrame with two columns: nomem_encr and\n",
    "    prediction. The nomem_encr column in the new DataFrame replicates the\n",
    "    corresponding column from the input DataFrame. The prediction\n",
    "    column contains predictions for each corresponding nomem_encr. Each\n",
    "    prediction is represented as a binary value: '0' indicates that the\n",
    "    individual did not have a child during 2021-2023, while '1' implies that\n",
    "    they did.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe for which predictions are to be made.\n",
    "    background_df (pd.DataFrame): The background dataframe for which predictions are to be made.\n",
    "    model_path (str): The path to the saved model file (which is the output of training.py).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A dataframe containing the identifiers and their corresponding predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    ## This script contains a bare minimum working example\n",
    "    if \"nomem_encr\" not in df.columns:\n",
    "        print(\"The identifier variable 'nomem_encr' should be in the dataset\")\n",
    "\n",
    "    # Load the model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Preprocess the fake / holdout data\n",
    "    df = clean_df(df, background_df)\n",
    "\n",
    "    # Exclude the variable nomem_encr if this variable is NOT in your model\n",
    "    vars_without_id = df.columns[df.columns != 'nomem_encr']\n",
    "\n",
    "    # Generate predictions from model, should be 0 (no child) or 1 (had child)\n",
    "    predictions = model.predict(df[vars_without_id])\n",
    "\n",
    "    # Output file should be DataFrame with two columns, nomem_encr and predictions\n",
    "    df_predict = pd.DataFrame(\n",
    "        {\"nomem_encr\": df[\"nomem_encr\"], \"prediction\": predictions}\n",
    "    )\n",
    "\n",
    "    # Return only dataset with predictions and identifier\n",
    "    return df_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e6b14-8485-4110-887d-e5ba8b4c7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_outcomes(fake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
